# Architectures module

Available architectures:

* LeNet-5, proposed by [LeCun et al., 1998], used in [Ganin et Al., 2016](https://jmlr.org/papers/volume17/15-239/15-239.pdf) for digit adaptation (MNIST to MNIST-M and MNIST to SVHN).
* SVHN, proposed by [Srivastava et al., 2014], used in [Ganin et Al., 2016](https://jmlr.org/papers/volume17/15-239/15-239.pdf)

## References

[LeCun et Al., 1998] LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.

[Ganin et Al., 2016] Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., ... & Lempitsky, V. (2016). Domain-adversarial training of neural networks. The journal of machine learning research, 17(1), 2096-2030.

[Srivastava et Al., 2014] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), 1929-1958.
